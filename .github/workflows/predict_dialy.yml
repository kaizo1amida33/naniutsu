n:
  schedule:
    - cron: "0 23 * * *"
  workflow_dispatch:

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  predict-and-deploy:
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas==2.2.2 numpy==1.26.4 scipy==1.11.4
          pip install scikit-learn==1.3.0 joblib==1.2.0
          pip install matplotlib seaborn

      - name: Check scraped data
        run: |
          echo "=== Scraped data ==="
          ls -lh *_v14.csv 2>/dev/null || echo "No data"

      - name: Run prediction
        run: |
          if [ -f closed_days.txt ]; then
            python workflow_predict_777_fixed.py \
              --model_dir model_28/model_dir.joblib \
              --closed closed_days.txt \
              --warmup_days 14
          else
            python workflow_predict_777_fixed.py \
              --model_dir model_28/model_dir.joblib \
              --warmup_days 14
          fi

      - name: Verify output
        run: |
          if [ ! -f predict_777.csv ]; then
            echo "ERROR: predict_777.csv not found"
            exit 1
          fi
          cat predict_777.csv

      - name: Generate HTML
        run: |
          mkdir -p public
          TIMESTAMP=$(date -u +"%Y-%m-%d %H:%M:%S UTC")
          TARGET_DATE=$(head -n 2 predict_777.csv | tail -n 1 | cut -d',' -f1)
          
          cat > public/index.html << 'HTMLEOF'
          <!DOCTYPE html>
          <html lang="ja">
          <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>K3 Prediction</title>
            <style>
              body { font-family: sans-serif; background: linear-gradient(135deg, #667eea, #764ba2); min-height: 100vh; padding: 20px; }
              .container { max-width: 900px; margin: 0 auto; background: white; border-radius: 15px; overflow: hidden; box-shadow: 0 20px 60px rgba(0,0,0,0.3); }
              header { background: linear-gradient(135deg, #667eea, #764ba2); color: white; padding: 30px; text-align: center; }
              h1 { margin: 0 0 10px; }
              .info { background: #f8f9fa; padding: 20px; }
              table { width: 100%; border-collapse: collapse; margin: 20px 0; }
              th, td { padding: 15px; text-align: left; border-bottom: 1px solid #ddd; }
              th { background: #667eea; color: white; }
              tr:hover { background: #f8f9fa; }
              .rank-1 { background: #fff3cd; font-weight: bold; }
              .rank-2 { background: #d1ecf1; }
              .rank-3 { background: #d4edda; }
              .download-btn { display: inline-block; margin: 10px; padding: 10px 20px; background: #28a745; color: white; text-decoration: none; border-radius: 5px; }
            </style>
          </head>
          <body>
            <div class="container">
              <header><h1>K3 Prediction</h1></header>
              <div class="info">
                <p>Generated: TIMESTAMP_PLACEHOLDER</p>
                <p>Target Date: TARGETDATE_PLACEHOLDER</p>
                <a href="predict_777.csv" class="download-btn">Download CSV</a>
              </div>
              <table><thead><tr>
          HTMLEOF
          
          sed -i "s/TIMESTAMP_PLACEHOLDER/${TIMESTAMP}/g" public/index.html
          sed -i "s/TARGETDATE_PLACEHOLDER/${TARGET_DATE}/g" public/index.html
          
          head -n1 predict_777.csv | tr ',' '\n' | while read col; do
            echo "<th>${col}</th>" >> public/index.html
          done
          
          echo "</tr></thead><tbody>" >> public/index.html
          
          tail -n +2 predict_777.csv | awk -F',' '{print (NR==1?"rank-1":(NR==2?"rank-2":"rank-3"))","$0}' | while IFS=',' read class cols; do
            echo "<tr class=\"${class}\">" >> public/index.html
            echo "${cols}" | tr ',' '\n' | while read val; do
              echo "<td>${val}</td>" >> public/index.html
            done
            echo "</tr>" >> public/index.html
          done
          
          echo "</tbody></table></div></body></html>" >> public/index.html

      - name: Copy CSV
        run: cp predict_777.csv public/

      - name: Upload Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

      - name: Deploy Pages
        id: deployment
        uses: actions/deploy-pages@v4

      - name: Commit results
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          mkdir -p predictions
          cp predict_777.csv predictions/predict_$(date +%Y%m%d).csv
          git add predictions/ || true
          git commit -m "Update prediction" || true
          git push || true
EOF
